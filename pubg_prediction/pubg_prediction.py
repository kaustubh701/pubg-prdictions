# -*- coding: utf-8 -*-
"""pubg-prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_GzkPC_NTJQrUapi33BVuErixlPKI8YO
"""

# Jovian Commit Essentials
# Please retain and execute this cell without modifying the contents for `jovian.commit` to work
!pip install jovian --upgrade -q
import jovian
jovian.set_project('pubg-prediction')
jovian.set_colab_id('1_GzkPC_NTJQrUapi33BVuErixlPKI8YO')

"""## Introduction

<img src="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.thenfapost.com%2Fwp-content%2Fuploads%2F2020%2F07%2FPUBG.jpg&f=1&nofb=1" alt="Pubg Poster" title="Pubg" width="1100" height="900"/>



PUBG is a player versus player shooter game in which up to one hundred players fight in a battle royale, a type of large-scale last man standing deathmatch where players fight to remain the last alive. Players can choose to enter the match solo, duo, or with a small team of up to four people. The last person or team alive wins the match.

Each match starts with players parachuting from a plane onto one of the four map. The plane's flight path across the map varies with each round, requiring players to quickly determine the best time to eject and parachute to the ground. Players start with no gear beyond customized clothing selections which do not affect gameplay. Once they land, players can search buildings, ghost towns and other sites to find weapons, vehicles, armor, and other equipment. These items are procedurally distributed throughout the map at the start of a match, with certain high-risk zones typically having better equipment. Killed players can be looted to acquire their gear as well. Players can opt to play either from the first-person or third-person perspective, each having their own advantages and disadvantages in combat and situational awareness; though server-specific settings can be used to force all players into one perspective to eliminate some advantages.

Every few minutes, the playable area of the map begins to shrink down towards a random location, with any player caught outside the safe area taking damage incrementally, and eventually being eliminated if the safe zone is not entered in time; in game, the players see the boundary as a shimmering blue wall that contracts over time. This results in a more confined map, in turn increasing the chances of encounters. During the course of the match, random regions of the map are highlighted in red and bombed, posing a threat to players who remain in that area. In both cases, players are warned a few minutes before these events, giving them time to relocate to safety. A plane will fly over various parts of the playable map occasionally at random, or wherever a player uses a flare gun, and drop a loot package, containing items which are typically unobtainable during normal gameplay. These packages emit highly visible red smoke, drawing interested players near it and creating further confrontations. On average, a full round takes no more than 30 minutes.

## Problem Statement

In a PUBG game, up to 100 players start in each match (matchId). Players can be on teams (groupId) which get ranked at the end of the game (winPlacePerc) based on how many other teams are still alive when they are eliminated. In game, players can pick up different munitions, revive downed-but-not-out (knocked) teammates, drive vehicles, swim, run, shoot, and experience all of the consequences -- such as falling too far or running themselves over and eliminating themselves.

You are provided with a large number of anonymized PUBG game stats, formatted so that each row contains one player's post-game stats. The data comes from matches of all types: solos, duos, squads, and custom; there is no guarantee of there being 100 players per match, nor at most 4 player per group.

You must create a model which predicts players' finishing placement based on their final stats, on a scale from 1 (first place) to 0 (last place).

## Importing the libraries

Before importing let's install all the libraries that are going to be used in the notebook.
"""

pip install numpy pandas matplotlib seaborn sklearn opendatasets xgboost --quiet

import os
import opendatasets as od
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.simplefilter('ignore')
pd.set_option("display.max_columns", None)

"""## Downloading the data

We can download the dataset from Kaggle directly within the Jupyter notebook using the `opendatasets` library.

The dataset is available at https://www.kaggle.com/c/pubg-finish-placement-prediction/data
"""

od.download('https://www.kaggle.com/c/pubg-finish-placement-prediction/data') # downloading the dataset by providing the url

"""The dataset is downloaded and extracted to the folder `pubg-finish-placement-prediction`."""

os.listdir('pubg-finish-placement-prediction') # list of files in the pubg-finish-placement-prediction directory

"""The file `train_V2.csv` contains the train data. 

The file `test_V2.csv` contains the test data.

Let's load it into a Pandas dataframe.

## Reading the dataset
"""

train_df = pd.read_csv('pubg-finish-placement-prediction/train_V2.csv') # reading the training data
test_df = pd.read_csv('pubg-finish-placement-prediction/test_V2.csv') # reading the testing data

"""## Feature Description:

1. DBNOs - Number of enemy players knocked.
2. assists - Number of enemy players this player damaged that were killed by teammates.
3. damageDealt - Total damage dealt. Note: Self inflicted damage is subtracted.
4. headshotKills - Number of enemy players killed with headshots.
5. heals - Number of healing items used.
6. Id - Player’s Id
7. killPlace - Ranking in match of number of enemy players killed.
8. killPoints - Kills-based external ranking of player. (Think of this as an Elo ranking where only kills matter.) If there is a value other than -1 in rankPoints, then any 0 in killPoints should be treated as a “None”.
9. killStreaks - Max number of enemy players killed in a short amount of time.
10. kills - Number of enemy players killed.
11. longestKill - Longest distance between player and player killed at time of death. This may be misleading, as downing a player and driving away may lead to a large longestKill stat.
12. matchDuration - Duration of match in seconds.
13. matchId - ID to identify match. There are no matches that are in both the training and testing set.
14. matchType - String identifying the game mode that the data comes from. The standard modes are “solo”, “duo”, “squad”, “solo-fpp”, “duo-fpp”, and “squad-fpp”; other modes are from events or custom matches.
15. rankPoints - Elo-like ranking of player. This ranking is inconsistent and is being deprecated in the API’s next version, so use with caution. Value of -1 takes place of “None”.
16. revives - Number of times this player revived teammates.
17. rideDistance - Total distance traveled in vehicles measured in meters.
18. roadKills - Number of kills while in a vehicle.
19. swimDistance - Total distance traveled by swimming measured in meters.
20. teamKills - Number of times this player killed a teammate.
21. vehicleDestroys - Number of vehicles destroyed.
22. walkDistance - Total distance traveled on foot measured in meters.
23. weaponsAcquired - Number of weapons picked up.
24. winPoints - Win-based external ranking of player. (Think of this as an Elo ranking where only winning matters.) If there is a value other than -1 in rankPoints, then any 0 in winPoints should be treated as a “None”.
25. groupId - ID to identify a group within a match. If the same group of players plays in different matches, they will have a different groupId each time.
26. numGroups - Number of groups we have data for in the match.
27. maxPlace - Worst placement we have data for in the match. This may not match with numGroups, as sometimes the data skips over placements.
28. boosts - Number of boost items used.
29. winPlacePerc - The target of prediction. 
This is a percentile winning placement, where 1 corresponds to 1st place, and 0 corresponds to last place in the match. It is calculated off of maxPlace, not numGroups, so it is possible to have missing chunks in a match.
"""

train_df.head() # first 5 rows of training data

"""Each record shows the individual performance of the players with respect to different aspect of the matches."""

test_df.head() # first 5 rows of testing data

print('The training data has {} rows and {} columns'.format(train_df.shape[0], train_df.shape[1]))
print('The test data has {} rows and {} columns'.format(test_df.shape[0], test_df.shape[1]))

"""Let's take a look at the datatypes of the column present in the dataset."""

train_df.info()

"""Except `matchType` all the other columns are of numerical datatypes while `matchType` is of the type object."""

train_df.describe() # descriptive statisitics of train data

train_df.isna().sum() # sum of na values in train data

test_df.isna().sum() # sum of na values in train data

"""We can delete the missing record since `winPlacePerc` is the target feature and it cannot be used for prediction."""

train_df.dropna(inplace = True) # dropping na values

"""## Exploratory Data Analysis 

Let's explore to dataset to find some insights that can be used building the ML models.

### MatchType:

There are 3 modes available in PUBG. One can play `solo`, or with a friend `(duo)`, or with 3 other friends `(squad)`.
"""

fig, ax = plt.subplots(1, 2, figsize=(12, 4))

train_df.groupby('matchId')['matchType'].first().value_counts().plot.bar(ax=ax[0])

'''
solo  <-- solo,solo-fpp,normal-solo,normal-solo-fpp
duo   <-- duo,duo-fpp,normal-duo,normal-duo-fpp,crashfpp,crashtpp
squad <-- squad,squad-fpp,normal-squad,normal-squad-fpp,flarefpp,flaretpp
'''
mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'

train_df['matchType'] = train_df['matchType'].apply(mapper)

train_df.groupby('matchId')['matchType'].first().value_counts().plot.bar(ax=ax[1])

"""### MaxPlace, NumGroups

__NumGroups :__ Number of groups we have data for in the match.

__MaxPlace :__ Worst placement we have data for in the match. This may not match with numGroups, as sometimes the data skips over placements.
"""

cols = ['numGroups','maxPlace']
des1 = train_df.groupby('matchType')[cols].agg(['min','mean','max']) # getting the 'min','mean','max' values of the grouped data
group = train_df.groupby(['matchType','matchId','groupId']).count().groupby(['matchType','matchId']).size().to_frame('Groups in match')
des2 = group.groupby('matchType')['Groups in match'].agg(['min','mean','max'])
pd.concat([des1, des2], axis = 1) # concatenating the two sets of grouped data

match = train_df.groupby(['matchType', 'matchId']).size().to_frame('players in match')
group = train_df.groupby(['matchType', 'matchId', 'groupId']).size().to_frame('players in group')
pd.concat([match.groupby('matchType').agg(['min', 'mean', 'max']), 
           group.groupby('matchType').agg(['min', 'mean', 'max'])], axis = 1)

"""### MatchDuration:

MatchDuration represents the duration of match in seconds.
"""

fig, ax = plt.subplots(1, 2, figsize = (14,6))

# plotting the distribution of the MatchDuration column
train_df['matchDuration'].hist(bins = 50, ax = ax[0])
train_df.query('matchDuration>=1200')['matchDuration'].hist(bins = 50, ax = ax[1]) # plotting the distribution of the MatchDuration were values are greater than 1200
plt.show();

"""### Assists:

Assist means to help, In PUBG if you have given damage to the enemy and your team-mate kills the same enemy as you have done some damage on it then it is counted as Assist Kill as both you and your team-mate as taken down the enemy.

(Or)

__Assists :__ Number of enemy players this player damaged that were killed by teammates.
"""

# distribution of assists column
sns.histplot(x = 'assists', data = train_df)
plt.title('Distribution of assists feature')# title
plt.show();

"""Here we can see that the distribution is right skewed which needs to be processed to make a normal distribution.

### Boosts:

There are three booster items in PUBG: Energy Drinks, Painkillers and Adrenaline Shots. These all increase your booster bar. Fill up your booster bar and it'll slowly replenish your health over time. The more it's full, the faster the health regeneration.

__Boosts :__ Number of boost items used.
"""

# distribution of assists column
plt.hist(x = 'boosts', data = train_df)
plt.title('Distribution of boosts feature')# title
plt.show();

"""Here also we can see that the distribution is right skewed which needs to be processed to make a normal distribution.

### DamageDealt

__DamageDealt :__ Total damage dealt. Note: Self inflicted damage is subtracted.
"""

plt.hist(x = 'damageDealt', data = train_df)
plt.title('Distribution of damage dealt feature')# title
plt.show();

"""Here also we can see that the distribution is right skewed which needs to be processed to make a normal distribution.

Let's loop through all numeric columns to explore the distributions.
"""

for col in train_df.select_dtypes(exclude = 'object').columns:
    train_df[col].plot(kind = 'hist')
    plt.title('Distribution of {} feature'.format(col))
    plt.show();

"""We can see that most of the columns are not normally distributed which might affect the final predictions.

### Correlation between features
"""

plt.figure(figsize = (40,15))

plt.title('Correlation Plot') # title
sns.heatmap(train_df.corr(), annot = True, cmap = 'rainbow') # heatmap to visualize the correlation
plt.show();

"""Here we can see thar with repect to the `winPlacePerc` features like `boosts`, `walkDistance`,`weaponsAcquired`, etc have a positive correlation.

## Feature Engineering

### HealthItems

We can add the value of `heals` and `boosts` column and create a new column `items`.
"""

train_df['health_items'] = train_df['heals'] + train_df['boosts']
test_df['health_items'] = test_df['heals'] + test_df['boosts']

# dropping the duplicate columns
#train_df.drop(columns = ['heals', 'boosts'], axis = 1, inplace = True)
#test_df.drop(columns = ['heals', 'boosts'], axis = 1, inplace = True)

"""### TotalDistance

Creating a new column `totalDistance` as a summation of `rideDistance`, `swimDistance`, `walkDistance`
"""

train_df['totalDistance'] = train_df['rideDistance'] + train_df['swimDistance'] + train_df['walkDistance']
test_df['totalDistance'] = test_df['rideDistance'] + test_df['swimDistance'] + test_df['walkDistance']

# dropping the duplicate columns
#train_df.drop(columns = ['rideDistance', 'swimDistance', 'walkDistance'], axis = 1, inplace = True)
#test_df.drop(columns = ['rideDistance', 'swimDistance', 'walkDistance'], axis = 1, inplace = True)

"""### KillsWithoutMoving

Creating a new column `killsWithoutMoving` using the `kills` and `totalDistance` columns to find the number of kills a player made without any movement.
"""

train_df['killsWithoutMoving'] = ((train_df['kills'] > 0) & (train_df['totalDistance'] == 0))
test_df['killsWithoutMoving'] = ((test_df['kills'] > 0) & (test_df['totalDistance'] == 0))

"""### Teamwork

Creating a new column `teamwork` as a summation of `assists` and `revives`
"""

train_df['teamwork'] = train_df['assists'] + train_df['revives']
test_df['teamwork'] = test_df['assists'] + test_df['revives']

# dropping the duplicate columns
#train_df.drop(columns = ['assists', 'revives'], axis =1, inplace = True)
#test_df.drop(columns = ['assists', 'revives'],axis =1, inplace = True)

"""### HeadShotKillRate

Calculating the rate of headshot kills and saving it as `headshot_kill_rate`
"""

train_df['headshot_kill_rate'] = train_df['headshotKills'] / train_df['kills']
test_df['headshot_kill_rate'] = test_df['headshotKills'] / test_df['kills']

# replacing nan values with 0 in train and test
train_df.replace(np.nan, 0, inplace = True)
test_df.replace(np.nan, 0, inplace = True)

# dropping the duplicate columns
#train_df.drop(columns = ['headshotKills', 'kills'], axis =1, inplace = True)
#test_df.drop(columns = ['headshotKills', 'kills'],axis =1, inplace = True)

# applying the already defined mapper function on the test data

test_df['matchType'] = test_df['matchType'].apply(mapper)

"""## Outlier Removal

### Kills without moving

It is impossible to kill the players without moving unless the player uses some kind of cheating methods. So we can consider those points as outliers.
"""

# getting the index of all the players who have kills_without_moving as True

idx_to_drop = train_df[train_df['killsWithoutMoving'] == True].index
len(idx_to_drop)

train_df.drop(index = idx_to_drop, inplace = True) # dropping the rows were players having kills_without_moving as True

"""#### Roadkills"""

train_df['roadKills'].unique() # all the unique values in the roadkills columns

train_df[train_df['roadKills'] >= 10] # getting the rows were the roadkills values are greater than or equal to 10

"""Here we can see that player c3e444f7d1289d drove 5 meters but killed 14 people with it. Which doesn't make sense."""

# dropping all the rows were the roadKills values are greater than or eqaul to 10

idx_to_drop = train_df[train_df['roadKills'] >= 10].index
train_df.drop(index = idx_to_drop, inplace = True)

"""#### Kills"""

plt.figure(figsize = (20, 6))
sns.countplot(train_df['kills']) # countplot of the kills columns
plt.show()

"""We can see that the maximum number of kills for a single player goes upto 72 which is not possible. Any number of kills above 20 can be consisered as outliers."""

# dropping all the rows wew the kills values are greater than 20

idx_to_drop = train_df[train_df['kills'] > 20].index
train_df.drop(index = idx_to_drop, inplace = True)

"""#### Longest Kill"""

# checking the distribution of longestKill column

sns.displot(train_df['longestKill'], bins=10)
plt.show()

"""We can see that the maximum kill distance is 1km which is not normal. So we can consider them as outliers and drop them."""

# dropping the rows were the longestKill is greater than or equal to 1000

idx_to_drop = train_df[train_df['longestKill'] >= 1000].index
train_df.drop(index = idx_to_drop, inplace = True)

"""#### Distance travelled"""

train_df[['walkDistance', 'rideDistance', 'swimDistance', 'totalDistance']].describe()

## walk distance
sns.histplot(train_df['walkDistance'])

# dropping the rows were the walkDistance is greater than or equal to 10000

idx_to_drop = train_df[train_df['walkDistance'] >= 10000].index
train_df.drop(index = idx_to_drop, inplace = True)

# dropping the rows were the rideDistance is greater than or equal to 20000

idx_to_drop = train_df[train_df['rideDistance'] >= 20000].index
train_df.drop(index = idx_to_drop, inplace = True)

## swin distance
sns.displot(train_df['swimDistance'])

# dropping the rows were the swimDistance is greater than or equal to 2000

idx_to_drop = train_df[train_df['swimDistance'] >= 2000].index
train_df.drop(index = idx_to_drop, inplace = True)

"""#### Weapons Acquired"""

plt.figure(figsize=(12,4))
sns.displot(train_df['weaponsAcquired'], bins=100) # distribution of weapons acquired
plt.show()

train_df['weaponsAcquired'].unique() # unique values of weaponsAcquired column

# dropping the rows were the weaponsAcquired is greater than or equal to 50

idx_to_drop = train_df[train_df['weaponsAcquired'] >= 50].index
train_df.drop(index = idx_to_drop, inplace = True)

"""#### Heals"""

plt.figure(figsize=(12,4))
sns.displot(train_df['heals'], bins=10) # distribution of heals column
plt.show()

# dropping the rows were the heals is greater than or equal to 40

idx_to_drop = train_df[train_df['heals'] >= 40].index
train_df.drop(index = idx_to_drop, inplace = True)

# dropping all the duplicate rows

cols_to_drop = ['heals', 'boosts','rideDistance', 'swimDistance', 'walkDistance', 'assists', 'revives', 'headshotKills', 'kills']
train_df.drop(cols_to_drop, axis = 1, inplace = True)
test_df.drop(cols_to_drop, axis = 1, inplace = True)

"""## Preparing the data for training

We'll perform the following steps to prepare the dataset for training:

* Create a train/test/validation split.
* Identify input and target columns.
* Identify numeric and categorical columns.
* Impute (fill) missing numeric values.
* Scale numeric values.
* Encode categorical columns to one-hot vectors.
"""

# dropping the id columns in the train data

train_id_cols = train_df[['Id', 'groupId', 'matchId']]
train_df.drop(columns = ['Id', 'groupId', 'matchId'], inplace = True)

"""### Encoding the categorical features

Since ML models cannot process categorical data we need to tranform those data to numerical data.
"""

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder() # instance of OneHotEncoder
encoder.fit(train_df[['matchType']]) # fitting on the matchType column
encoder.categories_

one_hot = encoder.transform(train_df[['matchType']]).toarray() # transforming the matchType column to encoded column
one_hot

train_df[['duo', 'solo', 'squad']] = one_hot # creating new features that represent the encoded features
train_df.drop(columns = ['matchType'], inplace = True) # dropping the matchType column

"""Since our training dataset 4446966 rows to simply the training process we can take a random sample from the data to reduce the overall training time of the model."""

np.random.seed(42) # setting seed to have the same randomness
sample_size = 500000 # sample size of 500000
data = train_df.sample(sample_size) # new dataframe of the sampled data
data.head()

"""### Sepeating the depending and independent features.

Before building the ML model it is necessary to split the data so we can have two sets of data that helps us to have a comparison on the results produced by the model.
"""

X = data.drop('winPlacePerc', axis = 1) # independent features
y = data['winPlacePerc'] # dependent features

# list of all numeric cols
numeric_cols = X.select_dtypes(exclude = 'object').columns.tolist()

# list of all categorical cols
cat_cols = X.select_dtypes(include = 'object').columns.tolist()

X[numeric_cols].head()

"""### Performing Train Test split"""

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .2, random_state = 42) # setting validation data size as 20% of the data

"""### Scaling the numerical features

Since the numerical features in the training data are represented in different scales, it is important to scale to the data so that all the data are of the same scale.
"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler() # instance of StandardScaler

X_train_scaled = scaler.fit_transform(X_train) # fitting and transforming the training data
X_val_scaled = scaler.transform(X_val) # transforming the validation data

"""## Model 1

The first model that I am going to train is a RandomForestRegressor
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

model1 = RandomForestRegressor(n_jobs = -1, random_state = 100) # instance of RandomForestRegressor
model1.fit(X_train_scaled, y_train) # training the model

# making the predictions for X_train data

train_preds1 = model1.predict(X_train_scaled)
train_preds1

# error on the train data

train_rmse1 = mean_squared_error(train_preds1, y_train, squared = False)
print('The RMSE loss for the training data is {}'.format(train_rmse1))

# making predictions in the validation data

val_preds1 = model1.predict(X_val_scaled)
val_preds1

# checking the error on the validation data

val_rmse1 = mean_squared_error(val_preds1, y_val, squared = False)
print('The RMSE loss for the validation data is {}'.format(val_rmse1))

# finding the feature importance so we can know the importance of the features used by the model

# creating a dataframce to represent the feature importance
feature_imp = pd.DataFrame({
    'Feature' : X_train.columns,
    'Importance' : model1.feature_importances_
}).sort_values(by = 'Importance', ascending = False)

feature_imp.head(10) # top 10 importance features

plt.figure(figsize=(10,6))
plt.title('Feature Importance')
sns.barplot(data = feature_imp.head(10), x = 'Importance', y = 'Feature');

"""### Hyper-Parameter Tuning

* In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. 
* A hyperparameter is a parameter whose value is used to control the learning process.
"""

# function that takes the different arguments and trains the RandomForestRegressor
# return the rmse of the training and validation data

def test_params(**params):
    model = RandomForestRegressor(random_state = 100, n_jobs = -1, **params).fit(X_train_scaled, y_train)
    train_rmse = mean_squared_error(model.predict(X_train_scaled), y_train, squared=False)
    val_rmse = mean_squared_error(model.predict(X_val_scaled), y_val, squared=False)
    return train_rmse, val_rmse

# funcition to plot the training and validation error for the passed parameters
# using the test_params to find the training and validation error

def test_param_and_plot(param_name, param_values):
    train_rmse_ls, val_rmse_ls = [], [] 
    for value in param_values:
        params = {param_name: value}
        train_rmse, val_rmse = test_params(**params)
        train_rmse_ls.append(train_rmse)
        val_rmse_ls.append(val_rmse)
    plt.figure(figsize=(10,6))
    plt.title('Overfitting curve: ' + param_name)
    plt.plot(param_values, train_rmse_ls, 'b-o')
    plt.plot(param_values, val_rmse_ls, 'r-o')
    plt.xlabel(param_name)
    plt.ylabel('RMSE')
    plt.legend(['Training', 'Validation'])

"""#### n_estimators"""

# tuning n_estimators

test_param_and_plot('n_estimators', range(10, 150, 10)) # 90

"""Since `n_estimators` affect the training time of the model we can update the test_params() function so we can reduce the training time of the model."""

# updating the n_estimators in the function with the optimal value

def test_params(**params):
    model = RandomForestRegressor(n_estimators = 90, random_state = 100, n_jobs = -1, **params).fit(X_train_scaled, y_train)
    train_rmse = mean_squared_error(model.predict(X_train_scaled), y_train, squared=False)
    val_rmse = mean_squared_error(model.predict(X_val_scaled), y_val, squared=False)
    return train_rmse, val_rmse

"""#### max_depth"""

# tuning max_depth

test_param_and_plot('max_depth', range(2, 20, 2)) #12

"""#### min_samples_split"""

# tuning min_samples_split

test_param_and_plot('min_samples_split', range(5, 226, 20)) # 10

"""#### max_features"""

# tuning max_features

test_param_and_plot('max_features', ['auto', 'sqrt', 'log2', 0.2, 0.4, 0.6, 0.8, 1]) # 0.4

"""#### max_leaf_nodes"""

# tuning max_leaf_nodes

test_param_and_plot('max_leaf_nodes', range(100, 2200, 200)) # 750

"""#### min_samples_leaf"""

# tuning min_samples_leaf

test_param_and_plot('min_samples_leaf', range(10, 200, 10)) # 10

"""#### max_samples"""

# tuning max_samples

test_param_and_plot('max_samples', [0.2, 0.4, 0.6, 0.8, 1]) # 0.8

"""### Combining all the hyper parameters

Using the obtained hyper parametes values to redefine the model.
"""

model1 = RandomForestRegressor(n_estimators = 80, max_depth = 12, min_samples_split = 100,
                               max_features = 0.8, max_leaf_nodes = 2000, min_samples_leaf = 100,
                               max_samples = 0.8, n_jobs = -1, random_state = 100)
model1.fit(X_train_scaled, y_train)

# finding the predictions for X_train data
train_preds11 = model1.predict(X_train_scaled)

# error on the train data
train_rmse11 = mean_squared_error(train_preds11, y_train, squared = False)
print('The RMSE loss for the training data is {}'.format(train_rmse1))

# making predictions in the validation data
val_preds12 = model1.predict(X_val_scaled)

# checking the error on the validation data
val_rmse12 = mean_squared_error(val_preds12, y_val, squared = False)
print('The RMSE loss for the validation data is {}'.format(val_rmse1))

"""### Making predictions on the test data"""

test_df.head()

# dropping id columns on the test data

test_df_id = test_df[['Id','groupId','matchId']]
test_df.drop(columns = ['Id','groupId','matchId'], inplace = True)

# encoding MatchType column using One Hot Encoding

encoder = OneHotEncoder()
encoder.fit(test_df[['matchType']])
encoder.categories_

one_hot = encoder.transform(test_df[['matchType']]).toarray()
one_hot

#storing the encoded values back in the dataframe

test_df[['duo', 'solo', 'squad']] = one_hot
test_df.drop(columns = ['matchType'], inplace = True)

# scaling the numeric columns using StandardScaler

scaled_test_df = pd.DataFrame(scaler.transform(test_df), columns = test_df.columns)
scaled_test_df.head()

test_preds1 = model1.predict(scaled_test_df)

prediction_df1 = test_df_id
prediction_df1['predictions'] = test_preds1
prediction_df1.head()

"""## Model 2: XGBoost"""

from xgboost import XGBRegressor

model2 = XGBRegressor(random_state = 100, n_jobs = -1) # instance of xgboost regressor
model2.fit(X_train_scaled, y_train) # training the model

"""### Making predictions and evaluating the model"""

# finding the predictions for X_train data

train_preds2 = model2.predict(X_train_scaled)
train_preds2

# error on the train data

train_rmse2 = mean_squared_error(train_preds2, y_train, squared = False)
print('The RMSE loss for the training data is {}'.format(train_rmse2))

# making predictions in the validation data

val_preds2 = model2.predict(X_val_scaled)
val_preds2

# checking the error on the validation data

val_rmse2 = mean_squared_error(val_preds2, y_val, squared = False)
print('The RMSE loss for the validation data is {}'.format(val_rmse2))

"""### Feature Importance"""

feature_imp = pd.DataFrame({
    'Feature' : X_train.columns,
    'Importance' : model2.feature_importances_
}).sort_values(by = 'Importance', ascending = False)

feature_imp.head(10)

plt.figure(figsize=(10,6))
plt.title('Feature Importance')
sns.barplot(data = feature_imp.head(10), x = 'Importance', y = 'Feature');

"""### Hyper Parameter Tuning"""

# function that takes the different arguments and trains the RandomForestRegressor
# return the rmse of the training and validation data

def test_params(**params):
    model = XGBRegressor(random_state = 100, n_jobs=-1, **params).fit(X_train_scaled, y_train)
    train_rmse = mean_squared_error(model.predict(X_train_scaled), y_train, squared=False)
    val_rmse = mean_squared_error(model.predict(X_val_scaled), y_val, squared=False)
    return train_rmse, val_rmse

# funcition to plot the training and validation error for the passed parameters
# using the test_params to find the training and validation error

def test_param_and_plot(param_name, param_values):
    train_rmse_ls, val_rmse_ls = [], [] 
    for value in param_values:
        params = {param_name: value}
        train_rmse, val_rmse = test_params(**params)
        train_rmse_ls.append(train_rmse)
        val_rmse_ls.append(val_rmse)
    plt.figure(figsize=(10,6))
    plt.title('Overfitting curve: ' + param_name)
    plt.plot(param_values, train_rmse_ls, 'b-o')
    plt.plot(param_values, val_rmse_ls, 'r-o')
    plt.xlabel(param_name)
    plt.ylabel('RMSE')
    plt.legend(['Training', 'Validation'])

"""#### n_estimators"""

# tuning n_estimators

test_param_and_plot('n_estimators', [100, 200, 400, 600, 800, 1000]) # 200

# updating the n_estimators in the function with the optimal value

def test_params(**params):
    model = XGBRegressor(n_estimators = 200, random_state=100, n_jobs=-1, **params).fit(X_train_scaled, y_train)
    train_rmse = mean_squared_error(model.predict(X_train_scaled), y_train, squared=False)
    val_rmse = mean_squared_error(model.predict(X_val_scaled), y_val, squared=False)
    return train_rmse, val_rmse

"""#### max_depth"""

# tuning max_depth

test_param_and_plot('max_depth', range(2, 20, 2)) #8

"""#### booster"""

# tuning booster

test_param_and_plot('booster', ['gbtree', 'gblinear', 'dart']) #gbtree

"""#### min_child_weight"""

# tuning min_child_weight

test_param_and_plot('min_child_weight', [1, 3, 5, 7]) # 1

"""#### colsample_bytree"""

# tuning colsample_bytree

test_param_and_plot('colsample_bytree', [0.3, 0.4, 0.5 , 0.7]) # 0.7

"""#### max_delta_step """

# tuning max_delta_step

test_param_and_plot('max_delta_step', [0.2, 0.4, 0.6, 0.8, 1]) # 0.7

"""#### subsample """

# tuning subsample

test_param_and_plot('subsample', [0.2, 0.4, 0.6 , 0.8, 1])

"""#### gamma"""

# tuning gamma

test_param_and_plot('gamma', [0.00001, 0.0001, 0.001, 0.01, 0.1])

"""#### learning_rate"""

# tuning learning_rate

test_param_and_plot('learning_rate', [0.00001, 0.0001, 0.001, 0.01, 0.1])

"""### Combining all the hyper parameters

Using the obtained hyper parametes values to redefine the model.
"""

model2 = XGBRegressor(n_estimators = 200, max_depth = 6, learning_rate = 0.1,
                      booster = 'gbtree', gamma = 0.1, min_child_weight = 5,
                      colsample_bytree = 0.7, subsample = 0.8, max_delta_step = 0.4,
                      n_jobs = -1, random_state = 100)

model2.fit(X_train_scaled, y_train)

# finding the predictions for train data

train_preds21 = model2.predict(X_train_scaled)
print(train_preds21)
print()

# error on the train data

train_rmse21 = mean_squared_error(train_preds21, y_train, squared = False)
print('The RMSE loss for the training data is {}'.format(train_rmse2))

# making predictions in the validation data

val_preds22 = model2.predict(X_val_scaled)
print(val_preds22)
print()
# checking the error on the validation data

val_rmse22 = mean_squared_error(val_preds22, y_val, squared = False)
print('The RMSE loss for the validation data is {}'.format(val_rmse2))

"""### Prediction on test data"""

test_preds2 = model2.predict(scaled_test_df)
test_preds2

prediction_df2 = test_df_id
prediction_df2['predictions'] = test_preds2
prediction_df2.head()

random_forest = {'train_rmse(before_tuning)' : train_rmse1,
       'val_rmse(before_tuning)' : val_rmse1,
        'train_rmse(after_tuning)' : train_rmse11,
       'val_rmse(after_tuning)' : val_rmse12}
    
xgboost = {'train_rmse(before_tuning)' : train_rmse2,
       'val_rmse(before_tuning)' : val_rmse2,
        'train_rmse(after_tuning)' : train_rmse21,
       'val_rmse(after_tuning)' : val_rmse22}

# data frame with the erroe values for both the models.

final_prediction = pd.DataFrame([random_forest, xgboost], index = ['Random_Forest_Regressor', 'XGBoost_Regressor'])
final_prediction

# data frame containing the prediction for both the models

prediction_df = test_df_id
prediction_df['Random_Forest_Prediction'] = test_preds1
prediction_df['XGBoost_Prediction'] = test_preds2
prediction_df.head()

